{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def delete_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        for root, dirs, files in os.walk(folder_path, topdown=False):\n",
    "            for name in files:\n",
    "                os.remove(os.path.join(root, name))\n",
    "            for name in dirs:\n",
    "                os.rmdir(os.path.join(root, name))\n",
    "        os.rmdir(folder_path)\n",
    "    else:\n",
    "        print(f\"The folder {folder_path} does not exist\")\n",
    "\n",
    "delete_folder('./runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_dataset_all = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                               transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                              transform=transforms.ToTensor(), )\n",
    "\n",
    "subset_size = 55000  # The size of the subset I want\n",
    "indices = torch.randperm(len(train_dataset_all))[:subset_size]\n",
    "train_dataset = Subset(train_dataset_all, indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, params=None):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        if params:\n",
    "            self.linear.weight = nn.Parameter(params['weight'])\n",
    "            self.linear.bias = nn.Parameter(params['bias'])\n",
    "        # self.linear.weight = nn.Parameter(torch.zeros(output_dim - 1,input_dim))\n",
    "        # self.linear.bias = nn.Parameter(torch.zeros(output_dim - 1,input_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.linear.in_features)\n",
    "        # outputs = torch.nn.functional.softmax(self.linear(x))\n",
    "        outputs = self.linear(x)\n",
    "        return outputs\n",
    "\n",
    "class LogisticRegressionRestricted(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionRestricted, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim - 1)\n",
    "        # self.linear.weight = nn.Parameter(torch.zeros(output_dim - 1,input_dim))\n",
    "        # self.linear.bias = nn.Parameter(torch.zeros(output_dim - 1,input_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.linear.in_features)\n",
    "        # outputs = torch.nn.functional.softmax(self.linear(x))\n",
    "        outputs = self.linear(x)\n",
    "        zeros_for_last_class = torch.zeros(\n",
    "            (outputs.shape[0], 1),\n",
    "            device=x.device,\n",
    "            dtype=x.dtype\n",
    "        )\n",
    "        output_with_zeros = torch.cat((outputs, zeros_for_last_class), dim=1)\n",
    "        return output_with_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_dataset, writer=None, t=20, leave_out_indices=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    batch_num = 0\n",
    "    if leave_out_indices:\n",
    "        train_dataset = Subset(train_dataset, [i for i in range(len(train_dataset)) if i not in leave_out_indices])\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "    for epoch in range(t):\n",
    "        model.train() # Set the model to training mode\n",
    "        for batch_data, batch_labels in train_loader:\n",
    "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            batch_data = batch_data.view(-1, 28*28)\n",
    "            output = model(batch_data)\n",
    "            loss = criterion(output, batch_labels)\n",
    "            \n",
    "            if writer:\n",
    "                writer.add_scalar('training loss', loss, batch_num)\n",
    "            loss.backward()\n",
    "            optimizer.step(lambda: loss)\n",
    "            batch_num += 1\n",
    "            \n",
    "    return batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, test_dataset, device='cpu'):\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    incorrect_data_list, incorrect_label_list = [], []\n",
    "    with torch.no_grad():  # Disable gradient calculation during validation\n",
    "        for data, labels in test_loader:\n",
    "            # Transfer data to the appropriate device (CPU or GPU)\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(data.view(-1, 28*28))\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update validation metrics (e.g., accuracy)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            incorrect_data_list.append(data[predicted != labels])\n",
    "            incorrect_label_list.append(labels[predicted != labels])\n",
    "            \n",
    "    incorrect_data = torch.cat(incorrect_data_list, dim=0)\n",
    "    incorrect_label = torch.cat(incorrect_label_list, dim=0)\n",
    "    val_loss /= len(test_dataset)\n",
    "    val_accuracy = 100 * val_correct / len(test_dataset)\n",
    "    return val_loss, val_accuracy, incorrect_data, incorrect_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the baseline model in Adam Optimizer and calculate $L(z, \\hat{\\theta})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(28*28, 10)\n",
    "initial_params = {\"weight\": model.linear.weight.data.clone(), \"bias\": model.linear.bias.data.clone()}\n",
    "optimizer_adam = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n",
      "torch.float64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns/logistic_regression_10_mnist\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m----> 2\u001b[0m batch_num \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_adam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[66], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_dataset, writer, t, leave_out_indices)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(t):\n\u001b[1;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;66;03m# Set the model to training mode\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/torchvision/datasets/mnist.py:143\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    139\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/PIL/Image.py:3307\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3305\u001b[0m shape \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3306\u001b[0m ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape)\n\u001b[0;32m-> 3307\u001b[0m strides \u001b[38;5;241m=\u001b[39m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrides\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3309\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/logistic_regression_10_mnist') \n",
    "batch_num = train(model, optimizer_adam, criterion, train_dataset, writer, t=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0043, Validation Accuracy: 92.23%\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy, incorrect_data, incorrect_label = test(model, criterion, test_dataset, device='cuda:0')\n",
    "print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the baseline model in L-BFGS Optimizer and calculate $L(z, \\hat{\\theta})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lbfgs(model, optimizer, criterion, train_dataset, writer=None, t=20, leave_out_indices=None):\n",
    "    device = torch.device('cpu')\n",
    "    model = model.to(device)\n",
    "    batch_num = 0\n",
    "    if leave_out_indices:\n",
    "        train_dataset = Subset(train_dataset, [i for i in range(len(train_dataset)) if i not in leave_out_indices])\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "    for epoch in range(t):\n",
    "        model.train() # Set the model to training mode\n",
    "        for batch_data, batch_labels in train_loader:\n",
    "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "            \n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                batch_data_reshaped = batch_data.view(-1, 28*28)\n",
    "                output = model(batch_data_reshaped)\n",
    "                loss = criterion(output, batch_labels)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "            \n",
    "            loss_val = optimizer.step(closure)\n",
    "            if writer:\n",
    "                writer.add_scalar('training loss', loss_val, batch_num)\n",
    "            batch_num += 1\n",
    "    print(f\"epoch {epoch} finished\")        \n",
    "    return batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 finished\n"
     ]
    }
   ],
   "source": [
    "writer_lbfgs = SummaryWriter('runs/logistic_regression_10_mnist_lbfgs')\n",
    "params = {\"weight\": initial_params[\"weight\"].clone(), \"bias\": initial_params[\"bias\"].clone()}\n",
    "model_lbfgs = LogisticRegression(28*28, 10, params=params)\n",
    "optimizer_lbfgs = torch.optim.LBFGS(model_lbfgs.parameters())\n",
    "\n",
    "def criterion_l2(output, target, model):\n",
    "    loss = criterion(output, target)\n",
    "    l2_reg = 0.0\n",
    "    for param in model.parameters():\n",
    "        l2_reg += torch.norm(param, 2)**2\n",
    "    loss += 0.01 * l2_reg\n",
    "    return loss\n",
    "\n",
    "batch_num = train_lbfgs(model_lbfgs, optimizer_lbfgs, lambda x, y: criterion_l2(x, y, model_lbfgs), train_dataset, writer=writer_lbfgs, t=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0043, Validation Accuracy: 92.23%\n"
     ]
    }
   ],
   "source": [
    "val_loss_lbfgs, val_accuracy_lbfgs, incorrect_data_lbfgs, incorrect_label_lbfgs = test(model_lbfgs, lambda x, y: criterion_l2(x, y, model_lbfgs), test_dataset)\n",
    "print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy, incorrect_data, incorrect_label = val_loss_lbfgs, val_accuracy_lbfgs, incorrect_data_lbfgs, incorrect_label_lbfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate loss difference of leave-one-out retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "test_data_index = torch.randint(0, len(incorrect_data), (1,)).item()\n",
    "x_test, y_test = incorrect_data[test_data_index], incorrect_label[test_data_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_leave_one_out_loss_diff(model, initial_params, optimizer, criterion, test_data, test_label, leave_out_indices, t=5):\n",
    "    params = {\"weight\": initial_params[\"weight\"].clone(), \"bias\": initial_params[\"bias\"].clone()}\n",
    "    loss_z_test_with_z = criterion(model(test_data), test_label.view(1))\n",
    "    model_leave_one_out = LogisticRegression(28*28, 10, params=params)\n",
    "    optimizer_leave_one_out = optimizer(model_leave_one_out.parameters())\n",
    "    train(model_leave_one_out, optimizer_leave_one_out, criterion, train_dataset, t=t, leave_out_indices=leave_out_indices)\n",
    "    loss_z_test_without_z = criterion(model_leave_one_out(test_data), test_label.view(1))\n",
    "    leave_one_out_loss_diff = loss_z_test_without_z - loss_z_test_with_z\n",
    "    print(f\"loss_z_test_with_z: {loss_z_test_with_z}, loss_z_test_without_z: {loss_z_test_without_z}, leave_one_out_loss_diff: {leave_one_out_loss_diff}\")\n",
    "    return leave_one_out_loss_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_lbfgs_retrained = SummaryWriter('runs/logistic_regression_10_mnist_lbfgs_retrained')\n",
    "def calc_leave_one_out_loss_diff_lbfgs(model, initial_params, criterion, test_data, test_label, leave_out_indices, t=1):\n",
    "    params = {\"weight\": initial_params[\"weight\"].clone(), \"bias\": initial_params[\"bias\"].clone()}\n",
    "    loss_z_test_with_z = criterion(model(test_data), test_label.view(1))\n",
    "    model_leave_one_out = LogisticRegression(28*28, 10, params=params)\n",
    "    optimizer_leave_one_out = torch.optim.LBFGS(model_leave_one_out.parameters())\n",
    "    train_lbfgs(model_leave_one_out, optimizer_leave_one_out, criterion, train_dataset, writer=writer_lbfgs_retrained, t=t, leave_out_indices=leave_out_indices)\n",
    "    loss_z_test_without_z = criterion(model_leave_one_out(test_data), test_label.view(1))\n",
    "    leave_one_out_loss_diff = loss_z_test_without_z - loss_z_test_with_z\n",
    "    print(f\"loss_z_test_with_z: {loss_z_test_with_z}, loss_z_test_without_z: {loss_z_test_without_z}, leave_one_out_loss_diff: {leave_one_out_loss_diff}\")\n",
    "    return leave_one_out_loss_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 finished\n",
      "loss_z_test_with_z: 3.8284571170806885, loss_z_test_without_z: nan, leave_one_out_loss_diff: nan\n",
      "tensor(nan, grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# writer_retrain = SummaryWriter('runs/logistic_regression_10_mnist_retrain') \n",
    "x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "print(calc_leave_one_out_loss_diff_lbfgs(model_lbfgs, initial_params, criterion, x_test, y_test, []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_sample_dataset(dataset, t):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    \n",
    "    # Shuffle the indices\n",
    "    sampler = torch.utils.data.sampler.RandomSampler(dataset, num_samples=t)\n",
    "    sampled_dataloader = torch.utils.data.DataLoader(dataset, batch_size=500, sampler=sampler)\n",
    "    return sampled_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28]) tensor([7, 5, 4, 5, 1, 7, 9, 7, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "sample_loader = uniform_sample_dataset(train_dataset, 10)\n",
    "for batch_data, batch_labels in sample_loader:\n",
    "    print(batch_data.shape, batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_criterion_first_order_derivative(loss, model):\n",
    "    model.zero_grad()\n",
    "    # Compute the first-order gradient\n",
    "    loss.backward(create_graph=True)\n",
    "    param_grads = [ p.grad.flatten() for p in model.parameters() if p.requires_grad ]\n",
    "    param_grads = torch.cat(param_grads)\n",
    "    return param_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_second_order_derivative_list(loss, model):\n",
    "    model.zero_grad()\n",
    "    # Compute the first-order gradient\n",
    "    loss.backward(create_graph=True)\n",
    "    first_grads = [ (p.grad.flatten(), p) for p in model.parameters() if p.requires_grad ]\n",
    "    # Compute the second-order gradient\n",
    "    second_grads = []\n",
    "    for first_grad, p in first_grads:\n",
    "        sub_matrix = []\n",
    "        for i in range(first_grad.shape[0]):\n",
    "            sub_matrix.append(torch.autograd.grad(first_grad[i], p, create_graph=True)[0].flatten())\n",
    "        sub_matrix = torch.stack(sub_matrix)\n",
    "        second_grads.append(sub_matrix)\n",
    "    print(second_grads)\n",
    "    return second_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_criterion_second_order_derivative(loss, model):\n",
    "    model.zero_grad()\n",
    "    # Compute the first-order gradient\n",
    "    loss.backward(create_graph=True)\n",
    "    first_grads = [ p.grad.flatten() for p in model.parameters() if p.requires_grad ]\n",
    "    # Compute the second-order gradient\n",
    "    second_grads = []\n",
    "    for first_grad in first_grads:\n",
    "        row = []\n",
    "        for p in model.parameters():\n",
    "            sub_matrix = []\n",
    "            for i in range(first_grad.shape[0]):\n",
    "                sub_matrix.append(torch.autograd.grad(first_grad[i], p, create_graph=True)[0].flatten())\n",
    "            sub_matrix = torch.stack(sub_matrix)\n",
    "            row.append(sub_matrix)\n",
    "        row = torch.cat(row, dim=1)\n",
    "        second_grads.append(row)\n",
    "    second_grads = torch.cat(second_grads, dim=0)\n",
    "    return second_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = torch.nn.Linear(2, 2)\n",
    "test_model = LogisticRegression(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0115,  0.2502]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data_tensor = torch.tensor([[1.0, -2.0]], requires_grad=True)\n",
    "label_tensor = torch.tensor([1.0, 0.0])\n",
    "label_tensor_long = torch.tensor([0])\n",
    "\n",
    "print(test_model(data_tensor)-label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0115,  2.0230,  0.2502, -0.5004, -1.0115,  0.2502],\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor([[ 0.2458, -0.4915, -0.2458,  0.4915,  0.2458, -0.2458],\n",
      "        [-0.4915,  0.9831,  0.4915, -0.9831, -0.4915,  0.4915],\n",
      "        [-0.2458,  0.4915,  0.2458, -0.4915, -0.2458,  0.2458],\n",
      "        [ 0.4915, -0.9831, -0.4915,  0.9831,  0.4915, -0.4915],\n",
      "        [ 0.2458, -0.4915, -0.2458,  0.4915,  0.2458, -0.2458],\n",
      "        [-0.2458,  0.4915,  0.2458, -0.4915, -0.2458,  0.2458]],\n",
      "       grad_fn=<CatBackward0>) tensor(False)\n",
      "[tensor([[ 1., -2.,  0., -0.],\n",
      "        [-2.,  4.,  0., -0.],\n",
      "        [ 0., -0.,  1., -2.],\n",
      "        [ 0., -0., -2.,  4.]], grad_fn=<StackBackward0>), tensor([[1., 0.],\n",
      "        [0., 1.]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zpvoh/miniconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/zpvoh/miniconda3/envs/py312/lib/python3.12/site-packages/torch/autograd/graph.py:825: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/torch/csrc/autograd/engine.cpp:1201.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1., -2.,  0., -0.],\n",
       "         [-2.,  4.,  0., -0.],\n",
       "         [ 0., -0.,  1., -2.],\n",
       "         [ 0., -0., -2.,  4.]], grad_fn=<StackBackward0>),\n",
       " tensor([[1., 0.],\n",
       "         [0., 1.]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(calc_criterion_first_order_derivative(torch.nn.MSELoss()(test_model(data_tensor), label_tensor), test_model))\n",
    "hessian = calc_criterion_second_order_derivative(criterion(test_model(data_tensor), label_tensor_long), test_model)\n",
    "print(hessian, torch.all(torch.linalg.eigvals(hessian).real >= 0))\n",
    "calc_loss_second_order_derivative_list(torch.nn.MSELoss()(test_model(data_tensor), label_tensor), test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7850])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zpvoh/miniconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7850, 7850])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "one_train_dataloader = uniform_sample_dataset(train_dataset, 1)\n",
    "for batch_data, batch_labels in one_train_dataloader:\n",
    "    batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "    print(calc_criterion_first_order_derivative(criterion(model(batch_data), batch_labels), model).shape)\n",
    "    hessian = calc_criterion_second_order_derivative(torch.nn.MSELoss()(model(batch_data), batch_labels.to(torch.float32)), model)\n",
    "    print(hessian.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hvp(y, w, v):\n",
    "    # First derivative\n",
    "    first_grads = torch.autograd.grad(y, w, retain_graph=True, create_graph=True)\n",
    "\n",
    "    first_grads = [g.flatten() for g in first_grads]\n",
    "    first_grads = torch.cat(first_grads, dim=0)\n",
    "    \n",
    "    # Calculate the element-wise product between the first gradients and the vector v\n",
    "    elemwise_products = torch.sum(first_grads * v)\n",
    "\n",
    "    # Second derivative\n",
    "    second_grads = torch.autograd.grad(elemwise_products, w, create_graph=True)\n",
    "    second_grads = [g.flatten() for g in second_grads]\n",
    "    second_grads = torch.cat(second_grads, dim=0)\n",
    "\n",
    "    return second_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.0690, 12.1380,  1.5012, -3.0024, -6.0690,  1.5012],\n",
      "       grad_fn=<MvBackward0>) tensor([-6.0690, 12.1380,  1.5012, -3.0024, -6.0690,  1.5012],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_306113/1375072365.py:3: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  expected = torch.matmul(calc_criterion_second_order_derivative(torch.nn.MSELoss()(test_model(data_tensor), label_tensor), test_model), vector.T)\n"
     ]
    }
   ],
   "source": [
    "params = [p for p in test_model.parameters()]\n",
    "vector = calc_criterion_first_order_derivative(torch.nn.MSELoss()(test_model(data_tensor), label_tensor), test_model)\n",
    "expected = torch.matmul(calc_criterion_second_order_derivative(torch.nn.MSELoss()(test_model(data_tensor), label_tensor), test_model), vector.T)\n",
    "vector._grad_fn = None\n",
    "test_model.zero_grad()\n",
    "actual = hvp(torch.nn.MSELoss()(test_model(data_tensor), label_tensor), params, vector)\n",
    "print(expected, actual)\n",
    "assert torch.equal(expected, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ihvp(train_dataset, test_data, test_label, model, criterion, t, r, device='cpu', reg_factor=0.91, scale=0.04, unique_datapoint=None, ihvp_summary_writer=SummaryWriter('runs/ihvp_sum_summary')):\n",
    "    ihvp_eval_avg = 0\n",
    "    test_data, test_label = test_data.to(device), test_label.to(device)\n",
    "    model = model.to(device)\n",
    "    def scaled_criterion(output, label):\n",
    "        return criterion(output, label) * scale\n",
    "    \n",
    "    vector = calc_criterion_first_order_derivative(scaled_criterion(model(test_data), test_label), model)\n",
    "    for i in range(r):\n",
    "        if unique_datapoint is None:\n",
    "            sampled_train_dataset = [(data, label) for data, label in uniform_sample_dataset(train_dataset, t)]\n",
    "        else:\n",
    "            sampled_train_dataset = []\n",
    "            for _ in range(t):\n",
    "                sampled_train_dataset.append(unique_datapoint)\n",
    "        # Step 1. Initialize the evaluation of the Hessian-vector product\n",
    "        ihvp_eval = vector\n",
    "        data_number = 0\n",
    "        for data, label in sampled_train_dataset:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            # Step 2. Compute the second order gradient of the loss w.r.t. the model parameters\n",
    "            model.zero_grad()\n",
    "            data_tensor = data.view(-1, 28*28)\n",
    "            params = [p for p in model.parameters()]\n",
    "            ihvp_eval._grad_fn = None\n",
    "            # Step 3. Compute the inner product between the Hessian matrix and the test gradient vector using HVP\n",
    "            second_grads = hvp(scaled_criterion(model(data_tensor), label), params, ihvp_eval)\n",
    "            hessian = calc_criterion_second_order_derivative(criterion(model(data_tensor), label), model)\n",
    "            regularized_hessian = scale * hessian + reg_factor * torch.eye(hessian.shape[0])\n",
    "            eig_hessian, eig_regularized_hessian = torch.linalg.eigvals(hessian), torch.linalg.eigvals(regularized_hessian)\n",
    "            # print(torch.linalg.norm(torch.eye(hessian.shape[0]), ord=2))\n",
    "            norm_diff_I_regularized_hessian = torch.linalg.norm(torch.eye(hessian.shape[0])-regularized_hessian, ord=2)\n",
    "            # print(norm_diff_I_regularized_hessian.sum())\n",
    "            # regularized_hessian_eigvals = torch.linalg.eigvals(regularized_hessian).real\n",
    "            # print(f\"is semi positive definite: {torch.all(regularized_hessian_eigvals >= 0)}\")\n",
    "            # print(f\"regularized hessain eigvals: {regularized_hessian_eigvals}\")\n",
    "            print(f\"norm_diff_I_regularized_hessian: {norm_diff_I_regularized_hessian}, {torch.max(torch.linalg.eigvals(torch.eye(hessian.shape[0])-regularized_hessian).real)}\")\n",
    "            # print(f\"max eigval for hessian: {torch.max(torch.abs(torch.linalg.eigvals(hessian).real))}\")\n",
    "            return (eig_hessian, eig_regularized_hessian, hessian)\n",
    "            # hessian_list = calc_loss_second_order_derivative_list(scaled_criterion(model(data_tensor), label), model)\n",
    "            # hessian_eigvals = torch.linalg.eigvals(hessian).real\n",
    "            # # diff = torch.norm(torch.eye(hessian.shape[0])-hessian, p=2)\n",
    "            # print(f\"is semi positive definite: {torch.all(hessian_eigvals >= 0)}\")\n",
    "            # print(f\"hessain eigvals: {torch.min(hessian_eigvals)}\")\n",
    "            # return hessian_eigvals\n",
    "            # print(f\"diff: {diff}, l2 for I: {torch.norm(torch.eye(hessian.shape[0]), p=2)}, hes: {hessian.sum()}, eig: {torch.max(torch.abs(torch.linalg.eigvals(hessian)))}\")\n",
    "            # return_grads_validation = torch.matmul(hessian, ihvp_eval.T)\n",
    "            # print(f\"diff: {torch.abs(return_grads.sum() - vector.sum())}, ihvp_eval: {ihvp_eval.sum()}, return_grads: {return_grads.sum()}, vector: {vector.sum()}\")\n",
    "            # print(f\"validation: {return_grads_validation.sum()}, hessian: {hessian.sum()}\")\n",
    "            ihvp_eval = (1 - reg_factor) * ihvp_eval + vector - second_grads\n",
    "            ihvp_summary_writer.add_scalar(f'ihvp_eval_sum_{i}', ihvp_eval.sum(), data_number)\n",
    "            data_number += 1\n",
    "        print(f\"ihvp iteration {i} done and ihvp sum is {ihvp_eval.sum()}\")\n",
    "        ihvp_eval_avg = i / (i + 1) * ihvp_eval_avg + 1 / (i + 1) * ihvp_eval         \n",
    "    return ihvp_eval_avg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = uniform_sample_dataset(test_dataset, 1)\n",
    "test_data_list = [(data, label) for data, label in test_dataloader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_data_loader  = uniform_sample_dataset(train_dataset, 1)\n",
    "uni_data_tuple = ()\n",
    "for data, label in uni_data_loader:\n",
    "    uni_data_tuple = (data.to(device), label.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data value sum: 83.81175994873047, Test data label: tensor([8])\n",
      "norm_diff_I_regularized_hessian: 0.9999964237213135, 0.9999954104423523\n"
     ]
    }
   ],
   "source": [
    "ihvp_summary_writer = SummaryWriter('runs/ihvp_sum_summary') \n",
    "model = model.to(device)\n",
    "for test_data, test_label in test_data_list:\n",
    "    test_data, test_label = test_data.to(device), test_label.to(device)\n",
    "    print(f\"Test data value sum: {test_data.sum()}, Test data label: {test_label}\")\n",
    "    model.zero_grad()\n",
    "    # ihvp_eval = ihvp(train_dataset, test_data, test_label, model, criterion, 20000, 1, reg_factor=5e-4, scale=0.04, ihvp_summary_writer=ihvp_summary_writer, unique_datapoint=uni_data_tuple)\n",
    "    eig_hessian, eig_reg_hessian, hessian = ihvp(train_dataset, test_data, test_label, model, criterion, 15000, 10, reg_factor=1e-5, scale=1e-3, ihvp_summary_writer=ihvp_summary_writer, unique_datapoint=uni_data_tuple)\n",
    "    # ihvp(train_dataset, test_data, test_label, model, criterion, 10000, 10, device='cpu', reg_factor=0, scale=0.8, ihvp_summary_writer=ihvp_summary_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_hessian_real = eig_hessian.real\n",
    "eig_reg_hessian_real = eig_reg_hessian.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = torch.eye(hessian.shape[0])\n",
    "\n",
    "reg_hessian = 0.04 * hessian + 1e-2 * I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9900, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.linalg.eigvals(I-reg_hessian).real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihvp_eval.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0238, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihvp_eval.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upweighting_loss_influence_function(train_dataset, upweighted_data, upweighted_label, test_data, test_label, model, criterion):\n",
    "    # Step 1. Compute the Hessian-vector product\n",
    "    ihvp_eval = ihvp(train_dataset, test_data, test_label, model, criterion)\n",
    "    # Step 2. Compute the influence function\n",
    "    influence = torch.dot(-ihvp_eval, calc_criterion_first_order_derivative(upweighted_data, upweighted_label, criterion, model))\n",
    "    return influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate loss difference of leave-one-out retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is a validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1096118 1.1403882]\n",
      "0.8903882032022074\n",
      "0.8903882032022074\n",
      "[[ 6. -4.]\n",
      " [-4.  4.]]\n",
      "[[ 5.99995419 -3.99996423]\n",
      " [-3.99996423  3.99997207]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "I = np.identity(2)\n",
    "A = np.array([[0.5,0.5],[0.5,0.75]])\n",
    "\n",
    "print(np.linalg.eigvals(A))\n",
    "\n",
    "print(np.linalg.norm(I - A, ord=2))\n",
    "U,S,Vh = np.linalg.svd(I - A)\n",
    "print(S.max())\n",
    "A_inv = I\n",
    "\n",
    "A_inv_ = np.linalg.inv(A)\n",
    "\n",
    "for i in range(100):\n",
    "    A_inv = A_inv + I - A@A_inv\n",
    "    \n",
    "print(A_inv_)\n",
    "print(A_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_semi_positive_definite(matrix):\n",
    "    return torch.all(torch.linalg.eigvals(matrix).real >= -1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1., 2.]], requires_grad=True) Parameter containing:\n",
      "tensor([-1.], requires_grad=True)\n",
      "tensor([[4.]], grad_fn=<AddmmBackward0>) tensor([0])\n",
      "hessain expected: tensor([[0.0177, 0.0353],\n",
      "        [0.0353, 0.0707]], grad_fn=<MulBackward0>), is semi positive definite: True\n",
      "tensor([[1.]], grad_fn=<SoftmaxBackward0>)\n",
      "[tensor([[0., 0.],\n",
      "        [0., 0.]], grad_fn=<StackBackward0>), tensor([[0.]], grad_fn=<StackBackward0>)]\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], grad_fn=<CatBackward0>) tensor(True)\n",
      "test_hessian_MSE: tensor([[2., 4., 2.],\n",
      "        [4., 8., 4.],\n",
      "        [2., 4., 2.]], grad_fn=<CatBackward0>), is_semi_positive_definite: True\n",
      "tensor([0., 0., 0.], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zpvoh/miniconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "logistic_test_model = LogisticRegression(2, 2)\n",
    "logistic_test_model.linear.weight.data = torch.tensor([[1.0, 2.0]])\n",
    "logistic_test_model.linear.bias.data = torch.tensor([-1.0])\n",
    "print(logistic_test_model.linear.weight, logistic_test_model.linear.bias)\n",
    "# logistic_test_model.weight.data = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "# logistic_test_model.bias.data = torch.tensor([1.0])\n",
    "\n",
    "input = torch.tensor([[1.0, 2.0]], requires_grad=True)\n",
    "output = logistic_test_model(input)\n",
    "label = torch.tensor([0])\n",
    "label_float = torch.tensor([1.0, 0.0])\n",
    "print(output, label)\n",
    "\n",
    "hessian_expected = torch.sigmoid(output[0][0]) * (1-torch.sigmoid(output[0][0])) * (input.T @ input)\n",
    "print(f\"hessain expected: {hessian_expected}, is semi positive definite: {is_semi_positive_definite(hessian_expected)}\")\n",
    "\n",
    "loss = torch.nn.functional.cross_entropy(output, label) * 1000\n",
    "loss_MSE = torch.nn.MSELoss()(output, label_float)\n",
    "\n",
    "# jaccobian = calc_criterion_first_order_derivative(loss, logistic_test_model)\n",
    "print(torch.softmax(output, dim=1))\n",
    "# print(jaccobian)\n",
    "\n",
    "test_hessian = calc_criterion_second_order_derivative(loss, logistic_test_model)\n",
    "test_hessian_list = calc_loss_second_order_derivative_list(loss, logistic_test_model)\n",
    "print(test_hessian, is_semi_positive_definite(test_hessian))\n",
    "test_hessian_MSE = calc_criterion_second_order_derivative(loss_MSE, logistic_test_model)\n",
    "print(f\"test_hessian_MSE: {test_hessian_MSE}, is_semi_positive_definite: {is_semi_positive_definite(test_hessian_MSE)}\")\n",
    "# print(torch.linalg.eigvals(test_hessian_list[0]).real)\n",
    "print(torch.linalg.eigvals(test_hessian).real)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
