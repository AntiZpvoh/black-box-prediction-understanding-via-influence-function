{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def delete_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        for root, dirs, files in os.walk(folder_path, topdown=False):\n",
    "            for name in files:\n",
    "                os.remove(os.path.join(root, name))\n",
    "            for name in dirs:\n",
    "                os.rmdir(os.path.join(root, name))\n",
    "        os.rmdir(folder_path)\n",
    "    else:\n",
    "        print(f\"The folder {folder_path} does not exist\")\n",
    "\n",
    "delete_folder('./runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-defined constants\n",
    "'''\n",
    "n = 55000  # The size of training set\n",
    "scale = 1e-2 # the scale factor for loss function\n",
    "damp = 1 # the damp factor to add L2 regularization in loss function\n",
    "criterion = torch.nn.CrossEntropyLoss() # loss function without scaling and regularization\n",
    "device = 'cuda:0'\n",
    "iteration = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section below, we would load training dataset and testing dataset from MNIST. We assign the training set size $n=55000$, which is accorded to the paper Understanding Black-box Predictions via Influence Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to mean=0.5, std=0.5\n",
    "])\n",
    "\n",
    "train_dataset_all = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                               transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                              transform=transform, )\n",
    "\n",
    "train_indices = torch.randperm(len(train_dataset_all))[:n]\n",
    "train_dataset = Subset(train_dataset_all, train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_list = []\n",
    "all_labels_list = []\n",
    "for i in range(len(train_dataset)):\n",
    "    data, label = train_dataset[i]\n",
    "    all_data_list.append(data)         # img shape: [1, 28, 28]\n",
    "    all_labels_list.append(label)\n",
    "\n",
    "train_data = torch.stack(all_data_list, dim=0).to(device)  # shape [n, 1, 28, 28]\n",
    "train_labels = torch.tensor(all_labels_list).to(device)        # shape [n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Logistic Regression Model Definition\n",
    "\n",
    "Below we defined the logistic regression model with training and testing method using L-BFGS optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, params=None):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        if params:\n",
    "            self.linear.weight = nn.Parameter(params['weight'])\n",
    "            self.linear.bias = nn.Parameter(params['bias'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.linear.in_features)\n",
    "        # outputs = torch.nn.functional.softmax(self.linear(x))\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lbfgs(model, criterion, train_data, train_labels, writer=None, t=20, leave_out_index=None):\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), lr=0.1, max_iter=50, line_search_fn='strong_wolfe')\n",
    "    # If there is a leave-out indices list, exclude these indies from the training set\n",
    "    if leave_out_index is not None:\n",
    "        train_data = torch.cat((train_data[:leave_out_index], train_data[leave_out_index + 1:]), dim=0) \n",
    "        train_labels = torch.cat((train_labels[:leave_out_index], train_labels[leave_out_index + 1:]), dim=0)        \n",
    "    \n",
    "    for epoch in range(t):  \n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_data)\n",
    "            loss = criterion(output, train_labels)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        \n",
    "        loss_val = optimizer.step(closure)\n",
    "        if writer:\n",
    "            writer.add_scalar('training loss', loss_val, epoch)\n",
    "        # print(f\"epoch {epoch} finished, loss={loss_val}\")        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Batch validation for the model\n",
    "'''\n",
    "def test(model, criterion, test_dataset):\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    incorrect_data_list, incorrect_label_list = [], []\n",
    "    with torch.no_grad():  # Disable gradient calculation during validation\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(data.view(-1, 28*28))\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update validation metrics (e.g., accuracy)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            incorrect_data_list.append(data[predicted != labels])\n",
    "            incorrect_label_list.append(labels[predicted != labels])\n",
    "            \n",
    "    incorrect_data = torch.cat(incorrect_data_list, dim=0)\n",
    "    incorrect_label = torch.cat(incorrect_label_list, dim=0)\n",
    "    val_loss /= len(test_dataset)\n",
    "    val_accuracy = 100 * val_correct / len(test_dataset)\n",
    "    return val_loss, val_accuracy, incorrect_data, incorrect_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the baseline model in L-BFGS Optimizer and calculate $L(z, \\hat{\\theta})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a summary writer for plotting training loss\n",
    "'''\n",
    "model_train_writer = SummaryWriter('runs/logistic_regression_10_mnist_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LogisticRegression(28*28, 10).to(device)\n",
    "# Store the initial parameter values for later leave-one-out retrain\n",
    "initial_params = {\"weight\": base_model.linear.weight.data.clone(), \"bias\": base_model.linear.bias.data.clone()}\n",
    "\n",
    "def criterion_l2(output, target, model):\n",
    "    loss = criterion(output, target)\n",
    "    l2_reg = 0.0\n",
    "    for param in model.parameters():\n",
    "        l2_reg += torch.norm(param, 2)**2\n",
    "    loss += damp * l2_reg\n",
    "    return loss * scale\n",
    "\n",
    "base_model_criterion = lambda x, y: criterion_l2(x, y, base_model)\n",
    "train_lbfgs(base_model, base_model_criterion, train_data, train_labels, writer=model_train_writer, t=iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0003, Validation Accuracy: 81.87%\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy, incorrect_data, incorrect_label = test(base_model, base_model_criterion, test_dataset)\n",
    "print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate loss difference of leave-one-out retraining\n",
    "\n",
    "According to the paper, we arbitrarily picked a wrongly-classified test point $z_{test}=(x_{test}, y_{test})$ as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_index = torch.randint(0, len(incorrect_data), (1,)).item()\n",
    "x_test, y_test = incorrect_data[test_data_index], incorrect_label[test_data_index].view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_leave_out_loss_diff(model, initial_params, criterion_l2, test_data, test_label, leave_out_index=None, t=1):\n",
    "    # Clone initial parameters\n",
    "    params = {\"weight\": initial_params[\"weight\"].clone(), \"bias\": initial_params[\"bias\"].clone()}\n",
    "    \n",
    "    # Calculate L(z_{test}, \\theta) which model is trained with all training points\n",
    "    loss_z_test_with_z = criterion_l2(model(test_data), test_label, model)\n",
    "    \n",
    "    # Train leave-one-out model\n",
    "    retrained_model = LogisticRegression(28*28, 10, params=params).to(device)\n",
    "    retrained_model_criterion = lambda x, y: criterion_l2(x, y, retrained_model)\n",
    "    train_lbfgs(retrained_model, retrained_model_criterion, train_data, train_labels, t=t, leave_out_index=leave_out_index)\n",
    "    \n",
    "    # Calculate L(z_{test}, \\theta_{-z}) which model is trained without data point z\n",
    "    loss_z_test_without_z = retrained_model_criterion(retrained_model(test_data), test_label)\n",
    "    \n",
    "    leave_out_loss_diff = loss_z_test_without_z - loss_z_test_with_z\n",
    "    # print(f\"loss_z_test_with_z: {loss_z_test_with_z}, loss_z_test_without_z: {loss_z_test_without_z}, leave_out_loss_diff: {leave_out_loss_diff}\")\n",
    "    return leave_out_loss_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Validate the functionality of calc_leave_out_loss_diff\n",
    "'''\n",
    "leave_out_loss_diff = calc_leave_out_loss_diff(base_model, initial_params, criterion_l2, x_test, y_test, t=iteration, leave_out_index=None)\n",
    "assert leave_out_loss_diff == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Influence Function\n",
    "\n",
    "### 0. Preparation\n",
    "\n",
    "Since in influence function stochastic estimation, we need to uniformly sample $t$ points from training set, an uniform sampling method would be neccessary to be defined as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_sample_dataset(dataset, t, batch_size=1):\n",
    "    sampler = torch.utils.data.sampler.RandomSampler(dataset, num_samples=t)\n",
    "    sampled_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "    return sampled_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method to calculate first order gradient of multivariable scalar function (in our case, loss function) for all the parameters:\n",
    "$$\\nabla_{\\theta} L(z, \\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_first_order_gradient(loss, model):\n",
    "    model.zero_grad()\n",
    "    # Compute the first-order gradient\n",
    "    loss.backward()\n",
    "    param_grads = [ p.grad.flatten() for p in model.parameters() if p.requires_grad ]\n",
    "    param_grads = torch.cat(param_grads)\n",
    "    return param_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method to calculate second order gradient of multivariable scalar function (i.e. Hessian matrix) for all the parameters:\n",
    "$$\\nabla^{2}_{\\theta} L(z, \\theta)$$\n",
    "\n",
    "Noted this method would not be used for any reason other than validation purpose, since it is not efficient and for our implementation, HVP (Hessian Vector Product) would be a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_second_order_gradient(loss, model):\n",
    "    model.zero_grad()\n",
    "    # Compute the first-order gradient\n",
    "    loss.backward(create_graph=True)\n",
    "    first_grads = [ p.grad.flatten() for p in model.parameters() if p.requires_grad ]\n",
    "    # Compute the second-order gradient\n",
    "    second_grads = []\n",
    "    for first_grad in first_grads:\n",
    "        row = []\n",
    "        for p in model.parameters():\n",
    "            # Compute every possible combination of differentiation variables for the parameters\n",
    "            sub_matrix = []\n",
    "            for i in range(first_grad.shape[0]):\n",
    "                sub_matrix.append(torch.autograd.grad(first_grad[i], p, create_graph=True)[0].flatten())\n",
    "            sub_matrix = torch.stack(sub_matrix)\n",
    "            row.append(sub_matrix)\n",
    "        row = torch.cat(row, dim=1)\n",
    "        second_grads.append(row)\n",
    "    second_grads = torch.cat(second_grads, dim=0)\n",
    "    return second_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. HVP (Hessian Vector Product) Calculation\n",
    "\n",
    "This method could accer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hvp(loss, params, vector):\n",
    "    # Compute the first-order gradient\n",
    "    first_grads = torch.autograd.grad(loss, params, create_graph=True)\n",
    "\n",
    "    first_grads = [g.flatten() for g in first_grads]\n",
    "    first_grads = torch.cat(first_grads, dim=0)\n",
    "    \n",
    "    # Calculate the product between the first gradients and the vector\n",
    "    first_grad_vector_product = torch.sum(first_grads * vector)\n",
    "\n",
    "    # Compute the second-order gradient\n",
    "    second_grads = torch.autograd.grad(first_grad_vector_product, params, create_graph=True)\n",
    "    second_grads = [g.flatten() for g in second_grads]\n",
    "    second_grads = torch.cat(second_grads, dim=0)\n",
    "\n",
    "    return second_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation for HVP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected HVP: tensor([-16.1753,  32.3507,   0.6734,  -1.3467, -16.1753,   0.6734],\n",
      "       grad_fn=<MvBackward0>) \n",
      "Actual HVP: tensor([-16.1753,  32.3507,   0.6734,  -1.3467, -16.1753,   0.6734],\n",
      "       grad_fn=<CatBackward0>) \n",
      "Diff Sum: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zpvoh/miniconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/zpvoh/miniconda3/envs/py312/lib/python3.12/site-packages/torch/autograd/graph.py:825: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/torch/csrc/autograd/engine.cpp:1201.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/tmp/ipykernel_8957/1855020473.py:13: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  expected = torch.matmul(calc_second_order_gradient(test_criterion(test_model(data_tensor), label_tensor), test_model), vector.T)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Validate the correctness of HVP's implementation\n",
    "'''\n",
    "\n",
    "test_model = LogisticRegression(2, 2)\n",
    "test_criterion = torch.nn.MSELoss()\n",
    "\n",
    "data_tensor = torch.tensor([[1.0, -2.0]], requires_grad=True)\n",
    "label_tensor = torch.tensor([1.0, 0.0])\n",
    "\n",
    "params = [p for p in test_model.parameters()]\n",
    "vector = calc_first_order_gradient(test_criterion(test_model(data_tensor), label_tensor), test_model)\n",
    "expected = torch.matmul(calc_second_order_gradient(test_criterion(test_model(data_tensor), label_tensor), test_model), vector.T)\n",
    "vector._grad_fn = None\n",
    "test_model.zero_grad()\n",
    "actual = hvp(torch.nn.MSELoss()(test_model(data_tensor), label_tensor), params, vector)\n",
    "print(f\"Expected HVP: {expected} \\nActual HVP: {actual} \\nDiff Sum: {(expected-actual).sum()}\")\n",
    "assert torch.equal(expected, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. IHVP (Inverse Hessian Vector Product) Calculation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ihvp(train_dataset, test_data, test_label, model, criterion, t, r, unique_datapoint=None, ihvp_summary_writer=None):\n",
    "    ihvp_eval_avg = 0\n",
    "    vector = calc_first_order_gradient(criterion(model(test_data), test_label), model)\n",
    "    for i in range(r):\n",
    "        # Arg unique_datapoint is used for debugging. It would generate an assigned single-data dataset\n",
    "        if unique_datapoint is None:\n",
    "            sampled_train_dataset = [(data, label) for data, label in uniform_sample_dataset(train_dataset, t)]\n",
    "        else:\n",
    "            sampled_train_dataset = []\n",
    "            for _ in range(t):\n",
    "                sampled_train_dataset.append(unique_datapoint)\n",
    "        # Step 1. Initialize the evaluation of the Hessian-vector product\n",
    "        ihvp_eval = vector\n",
    "        data_number = 0\n",
    "        for data, label in sampled_train_dataset:\n",
    "            # data, label = data.to(device), label.to(device)\n",
    "            # Step 2. Compute the second order gradient of the loss w.r.t. the model parameters\n",
    "            model.zero_grad()\n",
    "            data_tensor = data.view(-1, 28*28)\n",
    "            params = [p for p in model.parameters()]\n",
    "            ihvp_eval._grad_fn = None\n",
    "            # Step 3. Compute the inner product between the Hessian matrix and the test gradient vector using HVP\n",
    "            hvp_eval = hvp(criterion(model(data_tensor), label), params, ihvp_eval)\n",
    "            ihvp_eval = ihvp_eval + vector - hvp_eval\n",
    "            if ihvp_summary_writer:\n",
    "                ihvp_summary_writer.add_scalar(f'ihvp_eval_sum_{i}', ihvp_eval.sum(), data_number)\n",
    "            data_number += 1\n",
    "        print(f\"ihvp iteration {i} done and ihvp sum is {ihvp_eval.sum()}\")\n",
    "        ihvp_eval_avg = i / (i + 1) * ihvp_eval_avg + 1 / (i + 1) * ihvp_eval   \n",
    "    return ihvp_eval_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation for IHVP**: \n",
    "Check if IHVP successfully convergent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_data_loader  = uniform_sample_dataset(train_dataset, 1)\n",
    "uni_data_tuple = ()\n",
    "for data, label in uni_data_loader:\n",
    "    uni_data_tuple = (data.to(device), label.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data value sum: -649.058837890625, Test data label: tensor([2])\n",
      "ihvp iteration 0 done and ihvp sum is 0.00016865693032741547\n",
      "ihvp iteration 1 done and ihvp sum is 0.0001754038967192173\n",
      "ihvp iteration 2 done and ihvp sum is 0.00017857737839221954\n",
      "ihvp iteration 3 done and ihvp sum is 0.00017687492072582245\n",
      "ihvp iteration 4 done and ihvp sum is 0.00018056994304060936\n",
      "ihvp iteration 5 done and ihvp sum is 0.00017401669174432755\n",
      "ihvp iteration 6 done and ihvp sum is 0.00017768866382539272\n",
      "ihvp iteration 7 done and ihvp sum is 0.00017629656940698624\n",
      "ihvp iteration 8 done and ihvp sum is 0.00018225796520709991\n",
      "ihvp iteration 9 done and ihvp sum is 0.0001729121431708336\n",
      "tensor([ 6.7335e-04,  6.8843e-04,  6.8262e-04,  ..., -6.8951e-05,\n",
      "        -1.3876e-04, -1.1774e-04], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ihvp_summary_writer = SummaryWriter('runs/ihvp_sum_summary') \n",
    "print(f\"Test data value sum: {x_test.sum()}, Test data label: {y_test}\")\n",
    "ihvp_eval = ihvp(train_dataset, x_test, y_test, base_model, base_model_criterion, 5000, 10, ihvp_summary_writer=ihvp_summary_writer)\n",
    "print(ihvp_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihvp_eval.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Influence Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upweighting_loss_influence_function(s_test, train_dataset, upweighted_data, upweighted_label, test_data, test_label, model, criterion):\n",
    "    # Step 1. Compute the Inverse Hessian-vector product\n",
    "    # ihvp_eval = ihvp(train_dataset, test_data, test_label, model, criterion, 5000, 5)\n",
    "    # Step 2. Compute the influence function\n",
    "    first_grad = calc_first_order_gradient(criterion(model(upweighted_data), upweighted_label), model)\n",
    "    influence = torch.matmul(-s_test, first_grad)\n",
    "    return influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = upweighting_loss_influence_function(ihvp_eval, train_dataset, train_data[0], train_labels[0].view(1), x_test, y_test, base_model, base_model_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-8.3708e-08, grad_fn=<DivBackward0>),\n",
       " tensor(-8.2888e-07, grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-influence / n, calc_leave_out_loss_diff(base_model, initial_params, criterion_l2, x_test, y_test, t=iteration, leave_out_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 55000/55000 [00:15<00:00, 3554.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "influence_list = []\n",
    "for i in tqdm(range(n), desc=\"Processing\"):\n",
    "    influence = upweighting_loss_influence_function(ihvp_eval, train_dataset, train_data[i], train_labels[i].view(1), x_test, y_test, base_model, base_model_criterion)\n",
    "    predicted_diff = (influence, -influence / n, i)\n",
    "    influence_list.append(predicted_diff)\n",
    "    \n",
    "top_abs_500_list = sorted(influence_list, key=lambda pair: torch.abs(pair[0]), reverse=True)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# influence_leave_out_diff_list = []\n",
    "# for i in range(55000):\n",
    "#     influence = upweighting_loss_influence_function(ihvp_eval, train_dataset, train_data[i], train_labels[i].view(1), x_test, y_test, base_model, base_model_criterion)\n",
    "#     leave_out_loss_diff = calc_leave_out_loss_diff(base_model, initial_params, criterion_l2, x_test, y_test, t=iteration, leave_out_index=i)\n",
    "#     pair = (-influence / n, leave_out_loss_diff)\n",
    "#     influence_leave_out_diff_list.append(pair)\n",
    "#     print(i, pair)\n",
    "#     if i % 100 == 0:\n",
    "#         torch.save(influence_leave_out_diff_list, 'influence_leave_out_diff_list.pt')\n",
    "#         print(f\"index {i} saved\")\n",
    "    \n",
    "# top_500_list = sorted(influence_leave_out_diff_list, key=lambda pair: pair[0], reverse=True)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_abs_500_list = sorted(influence_list, key=lambda pair: torch.abs(pair[0]), reverse=True)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progressing...: 100%|██████████| 500/500 [20:06<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "influence_leave_out_diff_list = []\n",
    "for influence, predict, idx in tqdm(top_abs_500_list, desc=\"Progressing...\"):\n",
    "    leave_out_loss_diff = calc_leave_out_loss_diff(base_model, initial_params, criterion_l2, x_test, y_test, t=iteration, leave_out_index=idx)\n",
    "    pair = (predict, leave_out_loss_diff)\n",
    "    influence_leave_out_diff_list.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_leave_out_diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_500.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      2\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx,y\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m top_500_list:\n\u001b[1;32m      4\u001b[0m         file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m-\u001b[39mx\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     file\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "with open(\"top_500.csv\", \"w\") as file:\n",
    "    file.write(\"x,y\\n\")\n",
    "    for x, y in top_500_list:\n",
    "        file.write(f\"{-x.item()},{y.item()}\\n\")\n",
    "    file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"top_abs_500.csv\", \"w\") as file:\n",
    "    file.write(\"x,y\\n\")\n",
    "    for x, y in top_abs_500_list:\n",
    "        file.write(f\"{-x.item()},{y.item()}\\n\")\n",
    "    file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x_list, y_list = [], []\n",
    "for x, y in influence_leave_out_diff_list:\n",
    "    # if torch.abs(-x-y)>4*torch.abs(x):\n",
    "    #     continue\n",
    "    if y<0:\n",
    "        x = -x\n",
    "    x_list.append(x.item())\n",
    "    y_list.append(y.item())\n",
    "    \n",
    "x_dig = [-1e-5, 1e-5]\n",
    "y_dig = [-1e-5, 1e-5]\n",
    "plt.scatter(x_list, y_list)\n",
    "plt.plot(x_dig, y_dig)\n",
    "\n",
    "print(len(x_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
