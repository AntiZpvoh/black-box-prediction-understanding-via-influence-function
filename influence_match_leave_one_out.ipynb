{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def delete_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        for root, dirs, files in os.walk(folder_path, topdown=False):\n",
    "            for name in files:\n",
    "                os.remove(os.path.join(root, name))\n",
    "            for name in dirs:\n",
    "                os.rmdir(os.path.join(root, name))\n",
    "        os.rmdir(folder_path)\n",
    "    else:\n",
    "        print(f\"The folder {folder_path} does not exist\")\n",
    "\n",
    "delete_folder('./runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-defined constants\n",
    "'''\n",
    "n = 55000  # The size of training set\n",
    "scale = 1e-2 # the scale factor for loss function\n",
    "damp = 1 # the damp factor to add L2 regularization in loss function\n",
    "criterion = torch.nn.CrossEntropyLoss() # loss function without scaling and regularization\n",
    "device = 'cpu'\n",
    "iteration = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section below, we would load training dataset and testing dataset from MNIST. We assign the training set size $n=55000$, which is accorded to the paper Understanding Black-box Predictions via Influence Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5,), (0.5,))  # Normalize to mean=0.5, std=0.5\n",
    "])\n",
    "\n",
    "train_dataset_all = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                               transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                              transform=transform, )\n",
    "\n",
    "train_indices = torch.randperm(len(train_dataset_all))[:n]\n",
    "train_dataset = Subset(train_dataset_all, train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_list = []\n",
    "all_labels_list = []\n",
    "for i in range(len(train_dataset)):\n",
    "    data, label = train_dataset[i]\n",
    "    all_data_list.append(data)         # img shape: [1, 28, 28]\n",
    "    all_labels_list.append(label)\n",
    "\n",
    "train_data = torch.stack(all_data_list, dim=0).to(device)  # shape [n, 1, 28, 28]\n",
    "train_labels = torch.tensor(all_labels_list).to(device)        # shape [n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Logistic Regression Model Definition\n",
    "\n",
    "Below we defined the logistic regression model with training and testing method using L-BFGS optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, params=None):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        if params:\n",
    "            self.linear.weight = nn.Parameter(params['weight'])\n",
    "            self.linear.bias = nn.Parameter(params['bias'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.linear.in_features)\n",
    "        # outputs = torch.nn.functional.softmax(self.linear(x))\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lbfgs(model, criterion, train_data, train_labels, writer=None, t=20, leave_out_index=None):\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), lr=0.1, max_iter=50, line_search_fn='strong_wolfe')\n",
    "    # If there is a leave-out indices list, exclude these indies from the training set\n",
    "    if leave_out_index is not None:\n",
    "        train_data = torch.cat((train_data[:leave_out_index], train_data[leave_out_index + 1:]), dim=0) \n",
    "        train_labels = torch.cat((train_labels[:leave_out_index], train_labels[leave_out_index + 1:]), dim=0)        \n",
    "    \n",
    "    for epoch in range(t):  \n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_data)\n",
    "            loss = criterion(output, train_labels)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        \n",
    "        loss_val = optimizer.step(closure)\n",
    "        if writer:\n",
    "            writer.add_scalar('training loss', loss_val, epoch)\n",
    "        # print(f\"epoch {epoch} finished, loss={loss_val}\")        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Batch validation for the model\n",
    "'''\n",
    "def test(model, criterion, test_dataset):\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    incorrect_data_list, incorrect_label_list = [], []\n",
    "    with torch.no_grad():  # Disable gradient calculation during validation\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(data.view(-1, 28*28))\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update validation metrics (e.g., accuracy)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            incorrect_data_list.append(data[predicted != labels])\n",
    "            incorrect_label_list.append(labels[predicted != labels])\n",
    "            \n",
    "    incorrect_data = torch.cat(incorrect_data_list, dim=0)\n",
    "    incorrect_label = torch.cat(incorrect_label_list, dim=0)\n",
    "    val_loss /= len(test_dataset)\n",
    "    val_accuracy = 100 * val_correct / len(test_dataset)\n",
    "    return val_loss, val_accuracy, incorrect_data, incorrect_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the baseline model in L-BFGS Optimizer and calculate $L(z, \\hat{\\theta})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a summary writer for plotting training loss\n",
    "'''\n",
    "model_train_writer = SummaryWriter('runs/logistic_regression_10_mnist_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zpvoh/miniconda3/envs/py312/lib/python3.12/site-packages/torch/autograd/graph.py:825: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "base_model = LogisticRegression(28*28, 10).to(device)\n",
    "# Store the initial parameter values for later leave-one-out retrain\n",
    "initial_params = {\"weight\": base_model.linear.weight.data.clone(), \"bias\": base_model.linear.bias.data.clone()}\n",
    "\n",
    "def criterion_l2(output, target, model):\n",
    "    loss = criterion(output, target)\n",
    "    l2_reg = 0.0\n",
    "    for param in model.parameters():\n",
    "        l2_reg += torch.norm(param, 2)**2\n",
    "    loss += damp * l2_reg\n",
    "    return loss * scale\n",
    "\n",
    "base_model_criterion = lambda x, y: criterion_l2(x, y, base_model)\n",
    "train_lbfgs(base_model, base_model_criterion, train_data, train_labels, writer=model_train_writer, t=iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0003, Validation Accuracy: 77.13%\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy, incorrect_data, incorrect_label = test(base_model, base_model_criterion, test_dataset)\n",
    "print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate loss difference of leave-one-out retraining\n",
    "\n",
    "According to the paper, we arbitrarily picked a wrongly-classified test point $z_{test}=(x_{test}, y_{test})$ as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_index = torch.randint(0, len(incorrect_data), (1,)).item()\n",
    "x_test, y_test = incorrect_data[test_data_index], incorrect_label[test_data_index].view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_leave_out_loss_diff(model, initial_params, criterion_l2, test_data, test_label, leave_out_index=None, t=1):\n",
    "    # Clone initial parameters\n",
    "    params = {\"weight\": initial_params[\"weight\"].clone(), \"bias\": initial_params[\"bias\"].clone()}\n",
    "    \n",
    "    # Calculate L(z_{test}, \\theta) which model is trained with all training points\n",
    "    loss_z_test_with_z = criterion_l2(model(test_data), test_label, model)\n",
    "    \n",
    "    # Train leave-one-out model\n",
    "    retrained_model = LogisticRegression(28*28, 10, params=params).to(device)\n",
    "    retrained_model_criterion = lambda x, y: criterion_l2(x, y, retrained_model)\n",
    "    train_lbfgs(retrained_model, retrained_model_criterion, train_data, train_labels, t=t, leave_out_index=leave_out_index)\n",
    "    \n",
    "    # Calculate L(z_{test}, \\theta_{-z}) which model is trained without data point z\n",
    "    loss_z_test_without_z = retrained_model_criterion(retrained_model(test_data), test_label)\n",
    "    \n",
    "    leave_out_loss_diff = loss_z_test_without_z - loss_z_test_with_z\n",
    "    # print(f\"loss_z_test_with_z: {loss_z_test_with_z}, loss_z_test_without_z: {loss_z_test_without_z}, leave_out_loss_diff: {leave_out_loss_diff}\")\n",
    "    return leave_out_loss_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Validate the functionality of calc_leave_out_loss_diff\n",
    "'''\n",
    "leave_out_loss_diff = calc_leave_out_loss_diff(base_model, initial_params, criterion_l2, x_test, y_test, t=iteration, leave_out_index=None)\n",
    "assert leave_out_loss_diff == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Influence Function\n",
    "\n",
    "### 0. Preparation\n",
    "\n",
    "Since in influence function stochastic estimation, we need to uniformly sample $t$ points from training set, an uniform sampling method would be neccessary to be defined as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_sample_dataset(dataset, t, batch_size=1):\n",
    "    sampler = torch.utils.data.sampler.RandomSampler(dataset, num_samples=t)\n",
    "    sampled_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "    return sampled_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method to calculate first order gradient of multivariable scalar function (in our case, loss function) for all the parameters:\n",
    "$$\\nabla_{\\theta} L(z, \\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_first_order_gradient(loss, model):\n",
    "    model.zero_grad()\n",
    "    # Compute the first-order gradient\n",
    "    loss.backward()\n",
    "    param_grads = [ p.grad.flatten() for p in model.parameters() if p.requires_grad ]\n",
    "    param_grads = torch.cat(param_grads)\n",
    "    return param_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method to calculate second order gradient of multivariable scalar function (i.e. Hessian matrix) for all the parameters:\n",
    "$$\\nabla^{2}_{\\theta} L(z, \\theta)$$\n",
    "\n",
    "Noted this method would not be used for any reason other than validation purpose, since it is not efficient and for our implementation, HVP (Hessian Vector Product) would be a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_second_order_gradient(loss, model):\n",
    "    model.zero_grad()\n",
    "    # Compute the first-order gradient\n",
    "    loss.backward(create_graph=True)\n",
    "    first_grads = [ p.grad.flatten() for p in model.parameters() if p.requires_grad ]\n",
    "    # Compute the second-order gradient\n",
    "    second_grads = []\n",
    "    for first_grad in first_grads:\n",
    "        row = []\n",
    "        for p in model.parameters():\n",
    "            # Compute every possible combination of differentiation variables for the parameters\n",
    "            sub_matrix = []\n",
    "            for i in range(first_grad.shape[0]):\n",
    "                sub_matrix.append(torch.autograd.grad(first_grad[i], p, create_graph=True)[0].flatten())\n",
    "            sub_matrix = torch.stack(sub_matrix)\n",
    "            row.append(sub_matrix)\n",
    "        row = torch.cat(row, dim=1)\n",
    "        second_grads.append(row)\n",
    "    second_grads = torch.cat(second_grads, dim=0)\n",
    "    return second_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. HVP (Hessian Vector Product) Calculation\n",
    "\n",
    "This method could accer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hvp(loss, params, vector):\n",
    "    # Compute the first-order gradient\n",
    "    first_grads = torch.autograd.grad(loss, params, create_graph=True)\n",
    "\n",
    "    first_grads = [g.flatten() for g in first_grads]\n",
    "    first_grads = torch.cat(first_grads, dim=0)\n",
    "    \n",
    "    # Calculate the product between the first gradients and the vector\n",
    "    first_grad_vector_product = torch.sum(first_grads * vector)\n",
    "\n",
    "    # Compute the second-order gradient\n",
    "    second_grads = torch.autograd.grad(first_grad_vector_product, params, create_graph=True)\n",
    "    second_grads = [g.flatten() for g in second_grads]\n",
    "    second_grads = torch.cat(second_grads, dim=0)\n",
    "\n",
    "    return second_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation for HVP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected HVP: tensor([-7.3961, 14.7923,  3.1575, -6.3150, -7.3961,  3.1575],\n",
      "       grad_fn=<MvBackward0>) \n",
      "Actual HVP: tensor([-7.3961, 14.7923,  3.1575, -6.3150, -7.3961,  3.1575],\n",
      "       grad_fn=<CatBackward0>) \n",
      "Diff Sum: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zpvoh/miniconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/zpvoh/miniconda3/envs/py312/lib/python3.12/site-packages/torch/autograd/graph.py:825: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/torch/csrc/autograd/engine.cpp:1201.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/tmp/ipykernel_78212/1855020473.py:13: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  expected = torch.matmul(calc_second_order_gradient(test_criterion(test_model(data_tensor), label_tensor), test_model), vector.T)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Validate the correctness of HVP's implementation\n",
    "'''\n",
    "\n",
    "test_model = LogisticRegression(2, 2)\n",
    "test_criterion = torch.nn.MSELoss()\n",
    "\n",
    "data_tensor = torch.tensor([[1.0, -2.0]], requires_grad=True)\n",
    "label_tensor = torch.tensor([1.0, 0.0])\n",
    "\n",
    "params = [p for p in test_model.parameters()]\n",
    "vector = calc_first_order_gradient(test_criterion(test_model(data_tensor), label_tensor), test_model)\n",
    "expected = torch.matmul(calc_second_order_gradient(test_criterion(test_model(data_tensor), label_tensor), test_model), vector.T)\n",
    "vector._grad_fn = None\n",
    "test_model.zero_grad()\n",
    "actual = hvp(torch.nn.MSELoss()(test_model(data_tensor), label_tensor), params, vector)\n",
    "print(f\"Expected HVP: {expected} \\nActual HVP: {actual} \\nDiff Sum: {(expected-actual).sum()}\")\n",
    "assert torch.equal(expected, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. IHVP (Inverse Hessian Vector Product) Calculation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ihvp(train_dataset, test_data, test_label, model, criterion, t, r, unique_datapoint=None, ihvp_summary_writer=None):\n",
    "    ihvp_eval_avg = 0\n",
    "    vector = calc_first_order_gradient(criterion(model(test_data), test_label), model)\n",
    "    for i in range(r):\n",
    "        # Arg unique_datapoint is used for debugging. It would generate an assigned single-data dataset\n",
    "        if unique_datapoint is None:\n",
    "            sampled_train_dataset = [(data, label) for data, label in uniform_sample_dataset(train_dataset, t)]\n",
    "        else:\n",
    "            sampled_train_dataset = []\n",
    "            for _ in range(t):\n",
    "                sampled_train_dataset.append(unique_datapoint)\n",
    "        # Step 1. Initialize the evaluation of the Hessian-vector product\n",
    "        ihvp_eval = vector\n",
    "        data_number = 0\n",
    "        for data, label in sampled_train_dataset:\n",
    "            # data, label = data.to(device), label.to(device)\n",
    "            # Step 2. Compute the second order gradient of the loss w.r.t. the model parameters\n",
    "            model.zero_grad()\n",
    "            data_tensor = data.view(-1, 28*28)\n",
    "            params = [p for p in model.parameters()]\n",
    "            ihvp_eval._grad_fn = None\n",
    "            # Step 3. Compute the inner product between the Hessian matrix and the test gradient vector using HVP\n",
    "            hvp_eval = hvp(criterion(model(data_tensor), label), params, ihvp_eval)\n",
    "            ihvp_eval = ihvp_eval + vector - hvp_eval\n",
    "            if ihvp_summary_writer:\n",
    "                ihvp_summary_writer.add_scalar(f'ihvp_eval_sum_{i}', ihvp_eval.sum(), data_number)\n",
    "            data_number += 1\n",
    "        print(f\"ihvp iteration {i} done and ihvp sum is {ihvp_eval.sum()}\")\n",
    "        ihvp_eval_avg = i / (i + 1) * ihvp_eval_avg + 1 / (i + 1) * ihvp_eval   \n",
    "    return ihvp_eval_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation for IHVP**: \n",
    "Check if IHVP successfully convergent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_data_loader  = uniform_sample_dataset(train_dataset, 1)\n",
    "uni_data_tuple = ()\n",
    "for data, label in uni_data_loader:\n",
    "    uni_data_tuple = (data.to(device), label.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data value sum: 124.42745208740234, Test data label: tensor([5])\n",
      "ihvp iteration 0 done and ihvp sum is -6.201863288879395e-05\n",
      "ihvp iteration 1 done and ihvp sum is -6.214529275894165e-05\n",
      "ihvp iteration 2 done and ihvp sum is -6.070733070373535e-05\n",
      "ihvp iteration 3 done and ihvp sum is -6.366521120071411e-05\n",
      "ihvp iteration 4 done and ihvp sum is -6.160140037536621e-05\n",
      "ihvp iteration 5 done and ihvp sum is -6.211549043655396e-05\n",
      "ihvp iteration 6 done and ihvp sum is -6.072968244552612e-05\n",
      "ihvp iteration 7 done and ihvp sum is -6.172806024551392e-05\n",
      "ihvp iteration 8 done and ihvp sum is -6.446242332458496e-05\n",
      "ihvp iteration 9 done and ihvp sum is -6.189942359924316e-05\n",
      "tensor([ 2.0000e-06,  1.9896e-06, -2.9626e-06,  ...,  1.8880e-02,\n",
      "         7.3423e-03,  1.6718e-02], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ihvp_summary_writer = SummaryWriter('runs/ihvp_sum_summary') \n",
    "print(f\"Test data value sum: {x_test.sum()}, Test data label: {y_test}\")\n",
    "ihvp_eval = ihvp(train_dataset, x_test, y_test, base_model, base_model_criterion, 5000, 10, ihvp_summary_writer=ihvp_summary_writer)\n",
    "print(ihvp_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.3077e-05, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihvp_eval.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Influence Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upweighting_loss_influence_function(s_test, train_dataset, upweighted_data, upweighted_label, test_data, test_label, model, criterion):\n",
    "    # Step 1. Compute the Inverse Hessian-vector product\n",
    "    # ihvp_eval = ihvp(train_dataset, test_data, test_label, model, criterion, 5000, 5)\n",
    "    # Step 2. Compute the influence function\n",
    "    first_grad = calc_first_order_gradient(criterion(model(upweighted_data), upweighted_label), model)\n",
    "    influence = torch.matmul(-s_test, first_grad)\n",
    "    return influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence = upweighting_loss_influence_function(ihvp_eval, train_dataset, train_data[0], train_labels[0].view(1), x_test, y_test, base_model, base_model_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.8225e-08, grad_fn=<DivBackward0>),\n",
       " tensor(-9.5740e-07, grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-influence / n, calc_leave_out_loss_diff(base_model, initial_params, criterion_l2, x_test, y_test, t=iteration, leave_out_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 55000/55000 [00:16<00:00, 3381.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "influence_list = []\n",
    "for i in tqdm(range(n), desc=\"Processing\"):\n",
    "    influence = upweighting_loss_influence_function(ihvp_eval, train_dataset, train_data[i], train_labels[i].view(1), x_test, y_test, base_model, base_model_criterion)\n",
    "    predicted_diff = (influence, -influence / n, i)\n",
    "    influence_list.append(predicted_diff)\n",
    "    \n",
    "top_abs_500_list = sorted(influence_list, key=lambda pair: torch.abs(pair[0]), reverse=True)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_abs_500_list = sorted(influence_list, key=lambda pair: torch.abs(pair[0]), reverse=True)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_abs_500_1000_list = sorted(influence_list, key=lambda pair: torch.abs(pair[0]), reverse=True)[500:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progressing...: 100%|██████████| 500/500 [23:12<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "influence_leave_out_diff_list = []\n",
    "for influence, predict, idx in tqdm(top_abs_500_list, desc=\"Progressing...\"):\n",
    "    leave_out_loss_diff = calc_leave_out_loss_diff(base_model, initial_params, criterion_l2, x_test, y_test, t=iteration, leave_out_index=idx)\n",
    "    pair = (predict, leave_out_loss_diff)\n",
    "    influence_leave_out_diff_list.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progressing...: 100%|██████████| 500/500 [24:41<00:00,  2.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# influence_leave_out_diff_list_1000 = []\n",
    "for influence, predict, idx in tqdm(top_abs_500_1000_list, desc=\"Progressing...\"):\n",
    "    leave_out_loss_diff = calc_leave_out_loss_diff(base_model, initial_params, criterion_l2, x_test, y_test, t=iteration, leave_out_index=idx)\n",
    "    pair = (predict, leave_out_loss_diff)\n",
    "    influence_leave_out_diff_list.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x_list, y_list = [], []\n",
    "for y, x in influence_leave_out_diff_list:\n",
    "    # if torch.abs(-x-y)>4*torch.abs(x):\n",
    "    #     continue\n",
    "    x_list.append(x.item())\n",
    "    y_list.append(y.item())\n",
    "    \n",
    "x_dig = [0, 5e-6]\n",
    "y_dig = [0, 5e-6]\n",
    "plt.scatter(x_list, y_list)\n",
    "plt.plot(x_dig, y_dig)\n",
    "\n",
    "print(len(x_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1499.5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_influence_list = sorted(influence_list, key=lambda pair: torch.abs(pair[1]), reverse=True)[:3000]\n",
    "positive_count = 0\n",
    "positive_rank_avg = 0\n",
    "for i in range(len(sorted_influence_list)):\n",
    "    ele = sorted_influence_list[i]\n",
    "    if ele[1] > 0:\n",
    "        positive_rank_avg = positive_count / (positive_count + 1) * positive_rank_avg + 1 / (positive_count + 1) * i\n",
    "        positive_count += 1\n",
    "positive_count, positive_rank_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = [influence_list, influence_leave_out_diff_list]\n",
    "torch.save(stored, \"influence_lists.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted = torch.load(\"influence_lists.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sorted(influence_list, key=lambda pair: pair[0], reverse=True)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_abs_500_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
