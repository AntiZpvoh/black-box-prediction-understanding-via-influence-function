{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def delete_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        for root, dirs, files in os.walk(folder_path, topdown=False):\n",
    "            for name in files:\n",
    "                os.remove(os.path.join(root, name))\n",
    "            for name in dirs:\n",
    "                os.rmdir(os.path.join(root, name))\n",
    "        os.rmdir(folder_path)\n",
    "    else:\n",
    "        print(f\"The folder {folder_path} does not exist\")\n",
    "\n",
    "delete_folder('./runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-defined constants\n",
    "'''\n",
    "n = 55000  # The size of training set\n",
    "scale = 1e-3 # the scale factor for loss function\n",
    "damp = 1e-2 # the damp factor to add L2 regularization in loss function\n",
    "criterion = torch.nn.CrossEntropyLoss() # loss function without scaling and regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section below, we would load training dataset and testing dataset from MNIST. We assign the training set size $n=55000$, which is accorded to the paper Understanding Black-box Predictions via Influence Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Example: Normalize to mean=0.5, std=0.5\n",
    "])\n",
    "\n",
    "train_dataset_all = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                               transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                              transform=transform, )\n",
    "\n",
    "train_indices = torch.randperm(len(train_dataset_all))[:n]\n",
    "train_dataset = Subset(train_dataset_all, train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_list = []\n",
    "all_labels_list = []\n",
    "for i in range(len(train_dataset)):\n",
    "    data, label = train_dataset[i]\n",
    "    all_data_list.append(data)         # img shape: [1, 28, 28]\n",
    "    all_labels_list.append(label)\n",
    "\n",
    "train_data = torch.stack(all_data_list, dim=0)  # shape [n, 1, 28, 28]\n",
    "train_labels = torch.tensor(all_labels_list)        # shape [n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Logistic Regression Model Definition\n",
    "\n",
    "Below we defined the logistic regression model with training and testing method using L-BFGS optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, params=None):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        if params:\n",
    "            self.linear.weight = nn.Parameter(params['weight'])\n",
    "            self.linear.bias = nn.Parameter(params['bias'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.linear.in_features)\n",
    "        # outputs = torch.nn.functional.softmax(self.linear(x))\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lbfgs(model, criterion, train_data, train_labels, writer=None, t=20, leave_out_index=None):\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), lr=0.1, max_iter=50, line_search_fn='strong_wolfe')\n",
    "    # If there is a leave-out indices list, exclude these indies from the training set\n",
    "    if leave_out_index is not None:\n",
    "        train_data = torch.cat((train_data[:leave_out_index], train_data[leave_out_index + 1:]), dim=0) \n",
    "        train_labels = torch.cat((train_labels[:leave_out_index], train_labels[leave_out_index + 1:]), dim=0)        \n",
    "    \n",
    "    for epoch in range(t):  \n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_data)\n",
    "            loss = criterion(output, train_labels)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        \n",
    "        loss_val = optimizer.step(closure)\n",
    "        if writer:\n",
    "            writer.add_scalar('training loss', loss_val, epoch)\n",
    "        # print(f\"epoch {epoch} finished, loss={loss_val}\")        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Batch validation for the model\n",
    "'''\n",
    "def test(model, criterion, test_dataset):\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    incorrect_data_list, incorrect_label_list = [], []\n",
    "    with torch.no_grad():  # Disable gradient calculation during validation\n",
    "        for data, labels in test_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(data.view(-1, 28*28))\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update validation metrics (e.g., accuracy)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            incorrect_data_list.append(data[predicted != labels])\n",
    "            incorrect_label_list.append(labels[predicted != labels])\n",
    "            \n",
    "    incorrect_data = torch.cat(incorrect_data_list, dim=0)\n",
    "    incorrect_label = torch.cat(incorrect_label_list, dim=0)\n",
    "    val_loss /= len(test_dataset)\n",
    "    val_accuracy = 100 * val_correct / len(test_dataset)\n",
    "    return val_loss, val_accuracy, incorrect_data, incorrect_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the baseline model in L-BFGS Optimizer and calculate $L(z, \\hat{\\theta})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a summary writer for plotting training loss\n",
    "'''\n",
    "model_train_writer = SummaryWriter('runs/logistic_regression_10_mnist_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LogisticRegression(28*28, 10)\n",
    "# Store the initial parameter values for later leave-one-out retrain\n",
    "initial_params = {\"weight\": base_model.linear.weight.data.clone(), \"bias\": base_model.linear.bias.data.clone()}\n",
    "\n",
    "def criterion_l2(output, target, model):\n",
    "    loss = criterion(output, target) * scale\n",
    "    l2_reg = 0.0\n",
    "    for param in model.parameters():\n",
    "        l2_reg += torch.norm(param, 2)**2\n",
    "    loss += damp * l2_reg\n",
    "    return loss\n",
    "\n",
    "base_model_criterion = lambda x, y: criterion_l2(x, y, base_model)\n",
    "train_lbfgs(base_model, base_model_criterion, train_data, train_labels, writer=model_train_writer, t=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0000, Validation Accuracy: 62.23%\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy, incorrect_data, incorrect_label = test(base_model, base_model_criterion, test_dataset)\n",
    "print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate loss difference of leave-one-out retraining\n",
    "\n",
    "According to the paper, we arbitrarily picked a wrongly-classified test point $z_{test}=(x_{test}, y_{test})$ as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_index = torch.randint(0, len(incorrect_data), (1,)).item()\n",
    "x_test, y_test = incorrect_data[test_data_index], incorrect_label[test_data_index].view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_leave_out_loss_diff(model, initial_params, criterion_l2, test_data, test_label, leave_out_index=None, t=1):\n",
    "    # Clone initial parameters\n",
    "    params = {\"weight\": initial_params[\"weight\"].clone(), \"bias\": initial_params[\"bias\"].clone()}\n",
    "    \n",
    "    # Calculate L(z_{test}, \\theta) which model is trained with all training points\n",
    "    loss_z_test_with_z = criterion_l2(model(test_data), test_label, model)\n",
    "    \n",
    "    # Train leave-one-out model\n",
    "    retrained_model = LogisticRegression(28*28, 10, params=params)\n",
    "    retrained_model_criterion = lambda x, y: criterion_l2(x, y, retrained_model)\n",
    "    train_lbfgs(retrained_model, retrained_model_criterion, train_data, train_labels, t=t, leave_out_index=leave_out_index)\n",
    "    \n",
    "    # Calculate L(z_{test}, \\theta_{-z}) which model is trained without data point z\n",
    "    loss_z_test_without_z = retrained_model_criterion(retrained_model(test_data), test_label)\n",
    "    \n",
    "    leave_out_loss_diff = loss_z_test_without_z - loss_z_test_with_z\n",
    "    print(f\"loss_z_test_with_z: {loss_z_test_with_z}, loss_z_test_without_z: {loss_z_test_without_z}, leave_out_loss_diff: {leave_out_loss_diff}\")\n",
    "    return leave_out_loss_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_z_test_with_z: 0.002304940717294812, loss_z_test_without_z: 0.002304940717294812, leave_out_loss_diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Validate the functionality of calc_leave_out_loss_diff\n",
    "'''\n",
    "leave_out_loss_diff = calc_leave_out_loss_diff(base_model, initial_params, criterion_l2, x_test, y_test, t=10, leave_out_index=None)\n",
    "assert leave_out_loss_diff == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Influence Function\n",
    "\n",
    "### 0. Preparation\n",
    "\n",
    "Since in influence function stochastic estimation, we need to uniformly sample $t$ points from training set, an uniform sampling method would be neccessary to be defined as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_sample_dataset(dataset, t, batch_size=1):\n",
    "    sampler = torch.utils.data.sampler.RandomSampler(dataset, num_samples=t)\n",
    "    sampled_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "    return sampled_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method to calculate first order gradient of multivariable scalar function (in our case, loss function) for all the parameters:\n",
    "$$\\nabla_{\\theta} L(z, \\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_first_order_gradient(loss, model):\n",
    "    model.zero_grad()\n",
    "    # Compute the first-order gradient\n",
    "    loss.backward(create_graph=True)\n",
    "    param_grads = [ p.grad.flatten() for p in model.parameters() if p.requires_grad ]\n",
    "    param_grads = torch.cat(param_grads)\n",
    "    return param_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a method to calculate second order gradient of multivariable scalar function (i.e. Hessian matrix) for all the parameters:\n",
    "$$\\nabla^{2}_{\\theta} L(z, \\theta)$$\n",
    "\n",
    "Noted this method would not be used for any reason other than validation purpose, since it is not efficient and for our implementation, HVP (Hessian Vector Product) would be a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_second_order_gradient(loss, model):\n",
    "    model.zero_grad()\n",
    "    # Compute the first-order gradient\n",
    "    loss.backward(create_graph=True)\n",
    "    first_grads = [ p.grad.flatten() for p in model.parameters() if p.requires_grad ]\n",
    "    # Compute the second-order gradient\n",
    "    second_grads = []\n",
    "    for first_grad in first_grads:\n",
    "        row = []\n",
    "        for p in model.parameters():\n",
    "            # Compute every possible combination of differentiation variables for the parameters\n",
    "            sub_matrix = []\n",
    "            for i in range(first_grad.shape[0]):\n",
    "                sub_matrix.append(torch.autograd.grad(first_grad[i], p, create_graph=True)[0].flatten())\n",
    "            sub_matrix = torch.stack(sub_matrix)\n",
    "            row.append(sub_matrix)\n",
    "        row = torch.cat(row, dim=1)\n",
    "        second_grads.append(row)\n",
    "    second_grads = torch.cat(second_grads, dim=0)\n",
    "    return second_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. HVP (Hessian Vector Product) Calculation\n",
    "\n",
    "This method could accer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hvp(loss, params, vector):\n",
    "    # Compute the first-order gradient\n",
    "    first_grads = torch.autograd.grad(loss, params, create_graph=True)\n",
    "\n",
    "    first_grads = [g.flatten() for g in first_grads]\n",
    "    first_grads = torch.cat(first_grads, dim=0)\n",
    "    \n",
    "    # Calculate the product between the first gradients and the vector\n",
    "    first_grad_vector_product = torch.sum(first_grads * vector)\n",
    "\n",
    "    # Compute the second-order gradient\n",
    "    second_grads = torch.autograd.grad(first_grad_vector_product, params, create_graph=True)\n",
    "    second_grads = [g.flatten() for g in second_grads]\n",
    "    second_grads = torch.cat(second_grads, dim=0)\n",
    "\n",
    "    return second_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation for HVP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected HVP: tensor([ 0.5072, -1.0144, -5.7246, 11.4493,  0.5072, -5.7246],\n",
      "       grad_fn=<MvBackward0>) \n",
      "Actual HVP: tensor([ 0.5072, -1.0144, -5.7246, 11.4493,  0.5072, -5.7246],\n",
      "       grad_fn=<CatBackward0>) \n",
      "Diff Sum: 0.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Validate the correctness of HVP's implementation\n",
    "'''\n",
    "\n",
    "test_model = LogisticRegression(2, 2)\n",
    "test_criterion = torch.nn.MSELoss()\n",
    "\n",
    "data_tensor = torch.tensor([[1.0, -2.0]], requires_grad=True)\n",
    "label_tensor = torch.tensor([1.0, 0.0])\n",
    "\n",
    "params = [p for p in test_model.parameters()]\n",
    "vector = calc_first_order_gradient(test_criterion(test_model(data_tensor), label_tensor), test_model)\n",
    "expected = torch.matmul(calc_second_order_gradient(test_criterion(test_model(data_tensor), label_tensor), test_model), vector.T)\n",
    "vector._grad_fn = None\n",
    "test_model.zero_grad()\n",
    "actual = hvp(torch.nn.MSELoss()(test_model(data_tensor), label_tensor), params, vector)\n",
    "print(f\"Expected HVP: {expected} \\nActual HVP: {actual} \\nDiff Sum: {(expected-actual).sum()}\")\n",
    "assert torch.equal(expected, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. IHVP (Inverse Hessian Vector Product) Calculation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ihvp(train_dataset, test_data, test_label, model, criterion, t, r, unique_datapoint=None, ihvp_summary_writer=None):\n",
    "    ihvp_eval_avg = 0\n",
    "    vector = calc_first_order_gradient(criterion(model(test_data), test_label), model)\n",
    "    for i in range(r):\n",
    "        # Arg unique_datapoint is used for debugging. It would generate an assigned single-data dataset\n",
    "        if unique_datapoint is None:\n",
    "            sampled_train_dataset = [(data, label) for data, label in uniform_sample_dataset(train_dataset, t)]\n",
    "        else:\n",
    "            sampled_train_dataset = []\n",
    "            for _ in range(t):\n",
    "                sampled_train_dataset.append(unique_datapoint)\n",
    "        # Step 1. Initialize the evaluation of the Hessian-vector product\n",
    "        ihvp_eval = vector\n",
    "        data_number = 0\n",
    "        for data, label in sampled_train_dataset:\n",
    "            # Step 2. Compute the second order gradient of the loss w.r.t. the model parameters\n",
    "            model.zero_grad()\n",
    "            data_tensor = data.view(-1, 28*28)\n",
    "            params = [p for p in model.parameters()]\n",
    "            ihvp_eval._grad_fn = None\n",
    "            # Step 3. Compute the inner product between the Hessian matrix and the test gradient vector using HVP\n",
    "            second_grads = hvp(criterion(model(data_tensor), label), params, ihvp_eval)\n",
    "            ihvp_eval = ihvp_eval + vector - second_grads\n",
    "            if ihvp_summary_writer:\n",
    "                ihvp_summary_writer.add_scalar(f'ihvp_eval_sum_{i}', ihvp_eval.sum(), data_number)\n",
    "            data_number += 1\n",
    "        print(f\"ihvp iteration {i} done and ihvp sum is {ihvp_eval.sum()}\")\n",
    "        ihvp_eval_avg = i / (i + 1) * ihvp_eval_avg + 1 / (i + 1) * ihvp_eval         \n",
    "    return ihvp_eval_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation for IHVP**: \n",
    "Check if IHVP successfully convergent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data value sum: -452.02349853515625, Test data label: tensor([2])\n",
      "ihvp iteration 0 done and ihvp sum is 0.0005269250832498074\n",
      "ihvp iteration 1 done and ihvp sum is 0.000527174212038517\n",
      "ihvp iteration 2 done and ihvp sum is 0.0005267518572509289\n",
      "ihvp iteration 3 done and ihvp sum is 0.0005266759544610977\n",
      "ihvp iteration 4 done and ihvp sum is 0.0005274969153106213\n",
      "tensor([-0.0021, -0.0021, -0.0021,  ...,  0.0015,  0.0021,  0.0014],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ihvp_summary_writer = SummaryWriter('runs/ihvp_sum_summary') \n",
    "print(f\"Test data value sum: {x_test.sum()}, Test data label: {y_test}\")\n",
    "ihvp_eval = ihvp(train_dataset, x_test, y_test, base_model, base_model_criterion, 5000, 5, ihvp_summary_writer=ihvp_summary_writer)\n",
    "print(ihvp_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihvp_eval.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Influence Function Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upweighting_loss_influence_function(train_dataset, upweighted_data, upweighted_label, test_data, test_label, model, criterion):\n",
    "    # Step 1. Compute the Inverse Hessian-vector product\n",
    "    ihvp_eval = ihvp(train_dataset, test_data, test_label, model, criterion, 5000, 5)\n",
    "    # Step 2. Compute the influence function\n",
    "    first_grad = calc_first_order_gradient(criterion(model(upweighted_data), upweighted_label), model)\n",
    "    influence = torch.dot(-ihvp_eval, first_grad)\n",
    "    return influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ihvp iteration 0 done and ihvp sum is 0.0005280785262584686\n",
      "ihvp iteration 1 done and ihvp sum is 0.0005275940056890249\n",
      "ihvp iteration 2 done and ihvp sum is 0.0005273295100778341\n",
      "ihvp iteration 3 done and ihvp sum is 0.0005274936556816101\n",
      "ihvp iteration 4 done and ihvp sum is 0.0005275439471006393\n"
     ]
    }
   ],
   "source": [
    "influence = upweighting_loss_influence_function(train_dataset, train_data[0], train_labels[0].view(1), x_test, y_test, base_model, base_model_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_z_test_with_z: 0.002304940717294812, loss_z_test_without_z: 0.0023048899602144957, leave_out_loss_diff: -5.075708031654358e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(2.0989e-08, grad_fn=<DivBackward0>),\n",
       " tensor(-5.0757e-08, grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influence / n, calc_leave_out_loss_diff(base_model, initial_params, criterion_l2, x_test, y_test, t=10, leave_out_index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
